{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color='blue'>Data Science Project - EduPhile</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Made By***  <br> 1. Jumshaid Khan (FA17-BSE-004) <br> 2. Syeda Shane Zahra (FA17-BSE-043) <br><br> ***Scenario 02:*** Predicting student marks through answer provided by the teacher. (Vector Space Model Approach)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib as matplotlib\n",
    "import matplotlib.lines as mlines\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_answer</th>\n",
       "      <th>total_score</th>\n",
       "      <th>teacher_score</th>\n",
       "      <th>percentage</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>high risk problems are address in the prototyp...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>70</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>to simulate portions of the desired final prod...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a prototype program simulates the behaviors of...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>defined in the specification phase a prototype...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>it is used to let the users have a first idea ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      student_answer  total_score  \\\n",
       "0  high risk problems are address in the prototyp...            5   \n",
       "1  to simulate portions of the desired final prod...            5   \n",
       "2  a prototype program simulates the behaviors of...            5   \n",
       "3  defined in the specification phase a prototype...            5   \n",
       "4  it is used to let the users have a first idea ...            5   \n",
       "\n",
       "   teacher_score  percentage grade  \n",
       "0            3.5          70     C  \n",
       "1            5.0         100     A  \n",
       "2            4.0          80     B  \n",
       "3            5.0         100     A  \n",
       "4            3.0          60     D  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"assign01-q01.csv\"\n",
    "dataset = read_csv(url)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points:  145\n",
      "grade\n",
      "A    12\n",
      "B     1\n",
      "C     2\n",
      "D     3\n",
      "F    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points: \",dataset.size)\n",
    "print(dataset.groupby('grade').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenization of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jumsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jumsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Student Answer: high risk problems are address in the prototype program to make sure that the program is feasible.  a prototype may also be used to show a company that the software can be possibly programmed. \n",
      "\n",
      "\n",
      "Tokenized Answer: ['high', 'risk', 'problems', 'are', 'address', 'in', 'the', 'prototype', 'program', 'to', 'make', 'sure', 'that', 'the', 'program', 'is', 'feasible', 'a', 'prototype', 'may', 'also', 'be', 'used', 'to', 'show', 'a', 'company', 'that', 'the', 'software', 'can', 'be', 'possibly', 'programmed']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "print(\"Original Student Answer:\", dataset[\"student_answer\"][0],\"\\n\\n\")\n",
    "print(\"Tokenized Answer:\",tokenizer.tokenize(dataset[\"student_answer\"][0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_std_ans = [] \n",
    "for sentence in dataset[\"student_answer\"].values:\n",
    "    tk_std_ans.append(tokenizer.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokenized Answer:  ['high', 'risk', 'problems', 'are', 'address', 'in', 'the', 'prototype', 'program', 'to', 'make', 'sure', 'that', 'the', 'program', 'is', 'feasible', 'a', 'prototype', 'may', 'also', 'be', 'used', 'to', 'show', 'a', 'company', 'that', 'the', 'software', 'can', 'be', 'possibly', 'programmed']\n",
      "\n",
      "Tokenized Answer after stopwords removal:  ['high', 'risk', 'problems', 'address', 'prototype', 'program', 'make', 'sure', 'program', 'feasible', 'prototype', 'may', 'also', 'used', 'show', 'company', 'software', 'possibly', 'programmed']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "filtered_words = [word for word in tk_std_ans[0] if word not in stopwords.words('English')] \n",
    "print(\"Original Tokenized Answer: \", tk_std_ans[0])\n",
    "print()\n",
    "print(\"Tokenized Answer after stopwords removal: \", filtered_words)\n",
    "\n",
    "list_fw_std_ans = []\n",
    "\n",
    "for sentence in tk_std_ans:\n",
    "    fw_list = [word for word in sentence if word not in stopwords.words('English')]\n",
    "    list_fw_std_ans.append(fw_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal Student Answer:  ['high', 'risk', 'problems', 'address', 'prototype', 'program', 'make', 'sure', 'program', 'feasible', 'prototype', 'may', 'also', 'used', 'show', 'company', 'software', 'possibly', 'programmed']\n",
      "\n",
      "Lemmatized words:  ['high', 'risk', 'problem', 'address', 'prototype', 'program', 'make', 'sure', 'program', 'feasible', 'prototype', 'may', 'also', 'used', 'show', 'company', 'software', 'possibly', 'programmed']\n"
     ]
    }
   ],
   "source": [
    "print(\"Orignal Student Answer: \", list_fw_std_ans[0])\n",
    "\n",
    "lem_ans = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in list_fw_std_ans[0]]\n",
    "print()\n",
    "print(\"Lemmatized words: \", lem_ans)\n",
    "\n",
    "list_lem_std_ans = []\n",
    "\n",
    "for sentence in list_fw_std_ans:\n",
    "    lm_list = [word for word in sentence if word not in stopwords.words('English')]\n",
    "    list_lem_std_ans.append(lm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [high, risk, problems, address, prototype, pro...\n",
      "1     [simulate, portions, desired, final, product, ...\n",
      "2     [prototype, program, simulates, behaviors, por...\n",
      "3     [defined, specification, phase, prototype, sti...\n",
      "4     [used, let, users, first, idea, completed, pro...\n",
      "5           [find, problem, errors, program, finalized]\n",
      "6     [address, major, issues, creation, program, wa...\n",
      "7     [break, whole, program, prototype, programs, s...\n",
      "8     [provide, example, model, finished, program, p...\n",
      "9     [simulating, behavior, portion, desired, softw...\n",
      "10    [program, stimulates, behavior, portions, desi...\n",
      "11    [program, simulates, behavior, portions, desir...\n",
      "12    [lay, basics, give, starting, point, actual, p...\n",
      "13         [simulate, problem, solving, parts, problem]\n",
      "14    [prototype, program, provides, basic, groundwo...\n",
      "15    [prototype, program, part, specification, phas...\n",
      "16    [program, simulates, behavior, portions, desir...\n",
      "17    [provides, limited, proof, concept, verify, cl...\n",
      "18    [tests, main, function, program, leaving, fine...\n",
      "19    [get, early, feedback, users, early, stages, d...\n",
      "20    [simulates, behavior, portions, desired, softw...\n",
      "21    [simulates, behavior, portions, desired, softw...\n",
      "22    [prototype, program, used, problem, solving, c...\n",
      "23    [ease, understanding, problem, discussion, eas...\n",
      "24    [simulates, behavior, portions, desired, softw...\n",
      "25    [role, prototype, program, help, spot, key, pr...\n",
      "26    [prototype, program, gives, general, idea, end...\n",
      "27      [show, certain, part, program, works, supposed]\n",
      "28    [prototype, programming, approach, programming...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# creating our lemmitized student answers into series  \n",
    "data_std_ans = pd.Series(list_lem_std_ans) \n",
    "print(data_std_ans) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Teacher Answer: To simulate the behaviour of portions of the desired software product. \n",
      "\n",
      "\n",
      "Tokenized + Stopwords Removed + Lemmatized Teacher Answer: ['to' 'simulate' 'behaviour' 'portion' 'desired' 'software' 'product']\n"
     ]
    }
   ],
   "source": [
    "# preparing teacher answer\n",
    "t_quest = \"What is the role of a prototype program in problem solving?\"\n",
    "t_ans = \"To simulate the behaviour of portions of the desired software product.\"\n",
    "t_tkn_ans = tokenizer.tokenize(t_ans)\n",
    "t_fw_ans = [word for word in t_tkn_ans if word not in stopwords.words('English')]\n",
    "t_lem_ans = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in t_fw_ans]\n",
    "t_lem_ans = np.char.lower(t_lem_ans)\n",
    "\n",
    "print(\"Original Teacher Answer:\", t_ans,\"\\n\\n\")\n",
    "print(\"Tokenized + Stopwords Removed + Lemmatized Teacher Answer:\", t_lem_ans) \n",
    "\n",
    "teacher_ans = ' '.join(t_lem_ans)\n",
    "teacher_ans_list = [teacher_ans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF vectorizer for teacher answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['behaviour', 'desired', 'portion', 'product', 'simulate', 'software', 'to']\n",
      "  (0, 3)\t0.3779644730092272\n",
      "  (0, 5)\t0.3779644730092272\n",
      "  (0, 1)\t0.3779644730092272\n",
      "  (0, 2)\t0.3779644730092272\n",
      "  (0, 0)\t0.3779644730092272\n",
      "  (0, 4)\t0.3779644730092272\n",
      "  (0, 6)\t0.3779644730092272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "teacher_X = vectorizer.fit_transform(teacher_ans_list)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(teacher_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF vectorizer for students answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ans_doc = []\n",
    "\n",
    "def convertStdAnsToDocs(std_lem_data):\n",
    "    for ans in std_lem_data:\n",
    "        std_ans = ' '.join(ans)\n",
    "        std_ans_doc.append(std_ans)\n",
    "    return std_ans_doc\n",
    "\n",
    "convertStdAnsToDocs(data_std_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating Cosine Similarity between student and teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_tf_idf_query_similarity(vectorizer, docs_tfidf, query):\n",
    "    query_tfidf = vectorizer.transform([query])\n",
    "    cosineSimilarities = cosine_similarity(query_tfidf, docs_tfidf).flatten()\n",
    "    return cosineSimilarities\n",
    "\n",
    "std_score = []\n",
    "for std_ans in std_ans_doc:\n",
    "    std_score.append(get_tf_idf_query_similarity(vectorizer, teacher_X, std_ans)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std No.\t\tStudent Cosine Similarity Score\n",
      "1 \t\t [37.7964473]\n",
      "2 \t\t [65.46536707]\n",
      "3 \t\t [65.46536707]\n",
      "4 \t\t [65.46536707]\n",
      "5 \t\t [37.7964473]\n",
      "6 \t\t [0.]\n",
      "7 \t\t [0.]\n",
      "8 \t\t [37.7964473]\n",
      "9 \t\t [0.]\n",
      "10 \t\t [75.5928946]\n",
      "11 \t\t [65.46536707]\n",
      "12 \t\t [65.46536707]\n",
      "13 \t\t [0.]\n",
      "14 \t\t [37.7964473]\n",
      "15 \t\t [0.]\n",
      "16 \t\t [37.7964473]\n",
      "17 \t\t [65.46536707]\n",
      "18 \t\t [0.]\n",
      "19 \t\t [0.]\n",
      "20 \t\t [0.]\n",
      "21 \t\t [65.46536707]\n",
      "22 \t\t [65.46536707]\n",
      "23 \t\t [0.]\n",
      "24 \t\t [0.]\n",
      "25 \t\t [65.46536707]\n",
      "26 \t\t [0.]\n",
      "27 \t\t [37.7964473]\n",
      "28 \t\t [0.]\n",
      "29 \t\t [0.]\n"
     ]
    }
   ],
   "source": [
    "i=1;\n",
    "print(\"Std No.\\t\\tStudent Cosine Similarity Score\")\n",
    "for score in std_score:\n",
    "    print(i,\"\\t\\t\",score)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating VSM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing cosine similarity score into assignment score\n",
    "assign_score = []\n",
    "for score in std_score:\n",
    "    score = (float(score)/100)*5\n",
    "    assign_score.append(round(score,0)+1)\n",
    "\n",
    "teacher_scores = dataset.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean square Error is:  1.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = round(mean_squared_error(teacher_scores, assign_score),2)\n",
    "\n",
    "print(\"The mean square Error is: \", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
